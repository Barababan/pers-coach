"""
–ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –ö–ê–î–†–ò–†–û–í–ê–ù–ò–ï –í–ò–î–ï–û –¢–†–ï–ù–ï–†–ê
==========================================
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∏–¥–µ–æ, –Ω–∞—Ö–æ–¥–∏—Ç –≥—Ä–∞–Ω–∏—Ü—ã —Ç–µ–ª–∞ –Ω–∞ 15 –∫–∞–¥—Ä–∞—Ö,
–≤—ã—á–∏—Å–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π crop —á—Ç–æ–±—ã 80% –∫–∞–¥—Ä–æ–≤ –ø–æ–º–µ—â–∞–ª–∏—Å—å.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python autocrop_video.py input.mp4 output.mp4
    python autocrop_video.py input.mp4 output.mp4 --samples 20 --fit 85
    python autocrop_video.py input.mp4 output.mp4 --preview  # —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å crop –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏

–ü–æ—Å–ª–µ –∫—Ä–æ–ø–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ output.mp4 –Ω–∞ Google Drive –∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤ Colab.
"""

import cv2
import numpy as np
import argparse
import sys
import os


def get_person_mask(frame_bgr):
    """
    –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–∞—Å–∫–∏ —á–µ–ª–æ–≤–µ–∫–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç GrabCut + –¥–µ—Ç–µ–∫—Ü–∏—é –∫–æ–∂–∏ - –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è bbox.
    """
    h, w = frame_bgr.shape[:2]
    
    # –ú–µ—Ç–æ–¥ 1: –î–µ—Ç–µ–∫—Ü–∏—è –∫–æ–∂–∏ –≤ YCrCb
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    skin_mask = cv2.inRange(ycrcb, (0, 133, 77), (255, 173, 127))
    
    # –ú–µ—Ç–æ–¥ 2: –î–µ—Ç–µ–∫—Ü–∏—è –¥–≤–∏–∂–µ–Ω–∏—è/–ø–µ—Ä–µ–¥–Ω–µ–≥–æ –ø–ª–∞–Ω–∞ —á–µ—Ä–µ–∑ —Ü–≤–µ—Ç
    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —á–µ–ª–æ–≤–µ–∫ –≤ —Ü–µ–Ω—Ç—Ä–µ
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    
    # –°–æ–∑–¥–∞—ë–º –Ω–∞—á–∞–ª—å–Ω—É—é –º–∞—Å–∫—É - –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –≤ —Ü–µ–Ω—Ç—Ä–µ
    mask = np.zeros((h, w), np.uint8)
    
    # GrabCut –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è
    rect = (int(w * 0.1), int(h * 0.05), int(w * 0.8), int(h * 0.9))
    bgd_model = np.zeros((1, 65), np.float64)
    fgd_model = np.zeros((1, 65), np.float64)
    
    try:
        cv2.grabCut(frame_bgr, mask, rect, bgd_model, fgd_model, 3, cv2.GC_INIT_WITH_RECT)
        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
    except:
        # –ï—Å–ª–∏ GrabCut –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–∂—É
        mask2 = (skin_mask > 0).astype('uint8')
    
    # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –∫–æ–∂–∏
    combined = cv2.bitwise_or(mask2 * 255, skin_mask)
    
    # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
    combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)
    combined = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel)
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥—ã—Ä—ã
    contours, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        largest = max(contours, key=cv2.contourArea)
        filled = np.zeros_like(combined)
        cv2.drawContours(filled, [largest], -1, 255, -1)
        combined = filled
    
    return combined.astype(np.float32) / 255.0


def get_bbox_from_mask(mask, threshold=0.5):
    """–ü–æ–ª—É—á–∏—Ç—å bounding box –∏–∑ –º–∞—Å–∫–∏"""
    if mask.max() > 1:
        mask = mask.astype(np.float32) / 255.0
    
    binary = (mask > threshold).astype(np.uint8)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        return None
    
    largest = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(largest)
    
    return (x, y, x + w, y + h)


def analyze_video(video_path, num_samples=15, fit_percentage=80):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∏–¥–µ–æ –∏ –Ω–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π crop.
    
    Args:
        video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ
        num_samples: —Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
        fit_percentage: –∫–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫–∞–¥—Ä–æ–≤ –¥–æ–ª–∂–µ–Ω –ø–æ–º–µ—â–∞—Ç—å—Å—è
    
    Returns:
        dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ crop
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
        return None
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"üìπ –í–∏–¥–µ–æ: {width}x{height}, {total_frames} –∫–∞–¥—Ä–æ–≤, {fps:.1f} fps")
    print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {num_samples} –∫–∞–¥—Ä–æ–≤...")
    
    # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã
    sample_indices = np.linspace(0, total_frames - 1, num_samples, dtype=int)
    
    bboxes = []
    sample_frames = []
    
    for i, frame_idx in enumerate(sample_indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            continue
        
        print(f"   [{i+1}/{num_samples}] Frame {frame_idx}...", end=" ")
        
        mask = get_person_mask(frame)
        bbox = get_bbox_from_mask(mask)
        
        if bbox:
            bboxes.append(bbox)
            sample_frames.append((frame_idx, frame, mask, bbox))
            print(f"bbox: ({bbox[0]}, {bbox[1]}) - ({bbox[2]}, {bbox[3]})")
        else:
            print("—á–µ–ª–æ–≤–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    cap.release()
    
    if len(bboxes) < 3:
        print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞–¥—Ä–æ–≤ —Å —á–µ–ª–æ–≤–µ–∫–æ–º!")
        return None
    
    # === –í–´–ß–ò–°–õ–Ø–ï–ú –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ô CROP ===
    percentile_low = 100 - fit_percentage
    percentile_high = fit_percentage
    
    x_mins = [b[0] for b in bboxes]
    y_mins = [b[1] for b in bboxes]
    x_maxs = [b[2] for b in bboxes]
    y_maxs = [b[3] for b in bboxes]
    
    crop_x_min = int(np.percentile(x_mins, percentile_low))
    crop_y_min = int(np.percentile(y_mins, percentile_low))
    crop_x_max = int(np.percentile(x_maxs, percentile_high))
    crop_y_max = int(np.percentile(y_maxs, percentile_high))
    
    # Padding
    body_width = crop_x_max - crop_x_min
    body_height = crop_y_max - crop_y_min
    
    padding_x = int(body_width * 0.15)
    padding_y_top = int(body_height * 0.1)
    padding_y_bottom = int(body_height * 0.05)
    
    crop_x_min = max(0, crop_x_min - padding_x)
    crop_y_min = max(0, crop_y_min - padding_y_top)
    crop_x_max = min(width, crop_x_max + padding_x)
    crop_y_max = min(height, crop_y_max + padding_y_bottom)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º fit
    fits_count = sum(1 for bbox in bboxes 
                     if bbox[0] >= crop_x_min and bbox[1] >= crop_y_min 
                     and bbox[2] <= crop_x_max and bbox[3] <= crop_y_max)
    
    actual_fit = fits_count / len(bboxes) * 100
    
    crop_info = {
        "original_size": (width, height),
        "crop_box": (crop_x_min, crop_y_min, crop_x_max, crop_y_max),
        "crop_size": (crop_x_max - crop_x_min, crop_y_max - crop_y_min),
        "total_frames": total_frames,
        "fps": fps,
        "num_samples": len(bboxes),
        "frames_fit": fits_count,
        "fit_percentage": actual_fit,
        "sample_frames": sample_frames,
    }
    
    print(f"\n‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π crop:")
    print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª: {width}x{height}")
    print(f"   Crop box: ({crop_x_min}, {crop_y_min}) - ({crop_x_max}, {crop_y_max})")
    print(f"   –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {crop_x_max - crop_x_min}x{crop_y_max - crop_y_min}")
    print(f"   –ö–∞–¥—Ä–æ–≤ –ø–æ–º–µ—â–∞–µ—Ç—Å—è: {fits_count}/{len(bboxes)} ({actual_fit:.0f}%)")
    
    return crop_info


def show_preview(crop_info):
    """–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–≤—å—é –∫–∞–¥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è"""
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        print("‚ö†Ô∏è matplotlib –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–µ–≤—å—é –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
        return
    
    sample_frames = crop_info["sample_frames"]
    crop_box = crop_info["crop_box"]
    
    num_show = min(6, len(sample_frames))
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    for idx, ax in enumerate(axes.flat):
        if idx >= num_show:
            ax.axis('off')
            continue
        
        frame_idx, frame, mask, bbox = sample_frames[idx * len(sample_frames) // num_show]
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        ax.imshow(frame_rgb)
        
        # Person bbox (green)
        from matplotlib.patches import Rectangle
        rect_person = Rectangle(
            (bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1],
            fill=False, edgecolor='lime', linewidth=2
        )
        ax.add_patch(rect_person)
        
        # Crop area (red dashed)
        rect_crop = Rectangle(
            (crop_box[0], crop_box[1]), 
            crop_box[2] - crop_box[0], crop_box[3] - crop_box[1],
            fill=False, edgecolor='red', linewidth=2, linestyle='--'
        )
        ax.add_patch(rect_crop)
        
        ax.set_title(f'Frame {frame_idx}')
        ax.axis('off')
    
    plt.suptitle(
        f'AUTO CROP: {crop_info["crop_size"][0]}x{crop_info["crop_size"][1]} | '
        f'{crop_info["fit_percentage"]:.0f}% fit',
        fontsize=14, fontweight='bold'
    )
    plt.tight_layout()
    plt.show()


def crop_video(input_path, output_path, crop_info):
    """–ö—Ä–æ–ø–∞–µ—Ç –≤–∏–¥–µ–æ –ø–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –≥—Ä–∞–Ω–∏—Ü–∞–º"""
    crop_box = crop_info["crop_box"]
    x1, y1, x2, y2 = crop_box
    
    cap = cv2.VideoCapture(input_path)
    fps = crop_info["fps"]
    new_width = x2 - x1
    new_height = y2 - y1
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º mp4v –∫–æ–¥–µ–∫
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))
    
    total_frames = crop_info["total_frames"]
    print(f"\nüé¨ –ö—Ä–æ–ø–∞–µ–º –≤–∏–¥–µ–æ: {new_width}x{new_height}")
    
    frame_num = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Crop
        cropped = frame[y1:y2, x1:x2]
        out.write(cropped)
        
        frame_num += 1
        if frame_num % 100 == 0:
            progress = frame_num / total_frames * 100
            print(f"   {frame_num}/{total_frames} ({progress:.0f}%)")
    
    cap.release()
    out.release()
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    file_size = os.path.getsize(output_path) / (1024 * 1024)
    
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ: {output_path}")
    print(f"   –†–∞–∑–º–µ—Ä: {file_size:.1f} MB")
    print(f"   –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {new_width}x{new_height}")
    print(f"\nüì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –Ω–∞ Google Drive –∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤ Colab!")


def main():
    parser = argparse.ArgumentParser(
        description='–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫–∞–¥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Ç—Ä–µ–Ω–µ—Ä–∞',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  python autocrop_video.py squat.mp4 squat_cropped.mp4
  python autocrop_video.py squat.mp4 squat_cropped.mp4 --samples 20
  python autocrop_video.py squat.mp4 squat_cropped.mp4 --fit 85
  python autocrop_video.py squat.mp4 --preview
        """
    )
    
    parser.add_argument('input', help='–í—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ')
    parser.add_argument('output', nargs='?', help='–í—ã—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è --preview)')
    parser.add_argument('--samples', type=int, default=15, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (default: 15)')
    parser.add_argument('--fit', type=int, default=80, help='–ü—Ä–æ—Ü–µ–Ω—Ç –∫–∞–¥—Ä–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –ø–æ–º–µ—â–∞—Ç—å—Å—è (default: 80)')
    parser.add_argument('--preview', action='store_true', help='–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–≤—å—é, –Ω–µ –∫—Ä–æ–ø–∞—Ç—å')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.input}")
        sys.exit(1)
    
    if not args.preview and not args.output:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --preview")
        sys.exit(1)
    
    print("=" * 50)
    print("üé¨ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –ö–ê–î–†–ò–†–û–í–ê–ù–ò–ï –í–ò–î–ï–û")
    print("=" * 50)
    

    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–¥–µ–æ
    crop_info = analyze_video(args.input, args.samples, args.fit)
    
    if not crop_info:
        sys.exit(1)
    
    if args.preview:
        show_preview(crop_info)
    else:
        crop_video(args.input, args.output, crop_info)


if __name__ == "__main__":
    main()
