# Smart Mirror Pipeline - –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

## –û–±–∑–æ—Ä

–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ —Ç—Ä–µ–Ω–µ—Ä–∞: —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞, —Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è V11, cyclorama —Ñ–æ–Ω.

---

## 1. –õ–æ–∫–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç: –ê–≤—Ç–æ–∫–∞–¥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ

### –§–∞–π–ª: `autocrop_video.py`

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–µ–∑–∞–µ—Ç –≤–∏–¥–µ–æ –ø–æ –≥—Ä–∞–Ω–∏—Ü–∞–º —Ç–µ–ª–∞ —Ç—Ä–µ–Ω–µ—Ä–∞.

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
# –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
python3 autocrop_video.py squat.mp4 squat_cropped.mp4

# –° –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
python3 autocrop_video.py squat.mp4 squat_cropped.mp4 --samples 20 --fit 85

# –¢–æ–ª—å–∫–æ –ø—Ä–µ–≤—å—é (–±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏)
python3 autocrop_video.py squat.mp4 --preview
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `--samples N` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (default: 15)
- `--fit N` ‚Äî –ø—Ä–æ—Ü–µ–Ω—Ç –∫–∞–¥—Ä–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –ø–æ–º–µ—â–∞—Ç—å—Å—è (default: 80)
- `--preview` ‚Äî —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å bbox, –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
1. –ë–µ—Ä—ë—Ç N —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤ –∏–∑ –≤–∏–¥–µ–æ
2. –ù–∞ –∫–∞–∂–¥–æ–º –Ω–∞—Ö–æ–¥–∏—Ç —á–µ–ª–æ–≤–µ–∫–∞ —á–µ—Ä–µ–∑ GrabCut + –¥–µ—Ç–µ–∫—Ü–∏—è –∫–æ–∂–∏
3. –°–æ–±–∏—Ä–∞–µ—Ç bounding boxes –≤—Å–µ—Ö –∫–∞–¥—Ä–æ–≤
4. –í—ã—á–∏—Å–ª—è–µ—Ç crop –∫–æ—Ç–æ—Ä—ã–π –≤–º–µ—â–∞–µ—Ç –∑–∞–¥–∞–Ω–Ω—ã–π % –∫–∞–¥—Ä–æ–≤
5. –û–±—Ä–µ–∑–∞–µ—Ç –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ ffmpeg

**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** opencv-python, numpy, ffmpeg (—Å–∏—Å—Ç–µ–º–Ω—ã–π)

---

## 2. Google Colab: –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ

### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–∏–¥–µ–æ

1. –õ–æ–∫–∞–ª—å–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å autocrop:
   ```bash
   python3 autocrop_video.py squat.mp4 squat_cropped.mp4 --fit 85
   ```

2. –ó–∞–≥—Ä—É–∑–∏—Ç—å `squat_cropped.mp4` –Ω–∞ Google Drive

3. –ü–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É: –ü–ö–ú ‚Üí "–ü–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É" ‚Üí "–í—Å–µ —É –∫–æ–≥–æ –µ—Å—Ç—å —Å—Å—ã–ª–∫–∞"

4. –ò–∑–≤–ª–µ—á—å FILE_ID –∏–∑ —Å—Å—ã–ª–∫–∏:
   ```
   https://drive.google.com/file/d/XXXXXXXXXXXXX/view
                                    ‚Üë —ç—Ç–æ FILE_ID
   ```

### –ü–æ—Ä—è–¥–æ–∫ –∑–∞–ø—É—Å–∫–∞ —è—á–µ–µ–∫ –≤ Colab

#### –Ø—á–µ–π–∫–∞ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
```python
!nvidia-smi
```

#### –Ø—á–µ–π–∫–∞ 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
```python
%cd /content
!pip install onnxruntime-gpu gdown
!git clone https://github.com/ZHKKKe/MODNet.git
# –í–µ—Å–∞ —Å–∫–∞—á–∏–≤–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ gdown
```

#### –Ø—á–µ–π–∫–∞ 3: –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ —Å Google Drive
```python
import gdown
import os

file_id = "–í–ê–®_FILE_ID"  # <-- –∑–∞–º–µ–Ω–∏—Ç—å!
output_video = "/content/squat_cropped.mp4"

gdown.download(f"https://drive.google.com/uc?id={file_id}", output_video, quiet=False)

if os.path.exists(output_video):
    print(f"‚úÖ –í–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
    !ffprobe -v error -select_streams v:0 -show_entries stream=width,height,nb_frames -of csv=p=0 {output_video}
```

#### –Ø—á–µ–π–∫–∞ 4: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MODNet
```python
import torch
import sys
sys.path.insert(0, '/content/MODNet/src')
from models.modnet import MODNet
from torchvision import transforms

device = 'cuda' if torch.cuda.is_available() else 'cpu'

modnet = MODNet(backbone_pretrained=False)
modnet = torch.nn.DataParallel(modnet)
modnet.load_state_dict(torch.load('MODNet/pretrained/modnet_photographic_portrait_matting.ckpt', map_location='cpu'))
modnet = modnet.module.to(device)
modnet.eval()

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

print(f"‚úÖ MODNet –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ {device}")
```

#### –Ø—á–µ–π–∫–∞ 5: V11 —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
```python
import cv2
import numpy as np
from PIL import Image

# V11 –ù–∞—Å—Ç—Ä–æ–π–∫–∏ (–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≤–∏–¥)
V11_CONFIG = {
    'brightness_boost': 0.08,      # +8%
    'contrast': 1.12,              # +12%
    'lab_lift': 52,                # –û—Å–≤–µ—Ç–ª–µ–Ω–∏–µ —Ç–µ–Ω–µ–π –≤ LAB
    'skin_saturation_boost': 15,   # –ù–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å –∫–æ–∂–∏
    'warmth': {'red_boost': 1.03, 'blue_reduce': 0.97}
}

def process_frame_v11(frame_bgr, mask=None):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ —Å V11 –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
    img = frame_bgr.astype(np.float32) / 255.0
    
    # 1. –Ø—Ä–∫–æ—Å—Ç—å
    img = img + V11_CONFIG['brightness_boost']
    
    # 2. –ö–æ–Ω—Ç—Ä–∞—Å—Ç
    img = (img - 0.5) * V11_CONFIG['contrast'] + 0.5
    
    # 3. LAB lift (–æ—Å–≤–µ—Ç–ª–µ–Ω–∏–µ —Ç–µ–Ω–µ–π)
    img_uint8 = np.clip(img * 255, 0, 255).astype(np.uint8)
    lab = cv2.cvtColor(img_uint8, cv2.COLOR_BGR2LAB).astype(np.float32)
    L = lab[:,:,0]
    dark_mask = L < V11_CONFIG['lab_lift']
    lift_amount = (V11_CONFIG['lab_lift'] - L) * 0.3
    lab[:,:,0] = np.where(dark_mask, L + lift_amount, L)
    lab[:,:,0] = np.clip(lab[:,:,0], 0, 255)
    img_uint8 = cv2.cvtColor(lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
    img = img_uint8.astype(np.float32) / 255.0
    
    # 4. –¢–µ–ø–ª–æ—Ç–∞
    img[:,:,2] = img[:,:,2] * V11_CONFIG['warmth']['red_boost']    # R
    img[:,:,0] = img[:,:,0] * V11_CONFIG['warmth']['blue_reduce']  # B
    
    return np.clip(img * 255, 0, 255).astype(np.uint8)


def create_cyclorama_background(width, height, style="light"):
    """
    –°–æ–∑–¥–∞—ë—Ç cyclorama —Ñ–æ–Ω —Å 3D –≥–ª—É–±–∏–Ω–æ–π
    
    style: "dark" –∏–ª–∏ "light"
    """
    bg = np.zeros((height, width, 3), dtype=np.uint8)
    
    if style == "light":
        # –°–≤–µ—Ç–ª–∞—è —Å—Ç—É–¥–∏—è (–∫–∞–∫ Apple)
        wall_color = (180, 180, 185)   # –°–≤–µ—Ç–ª–æ-—Å–µ—Ä–∞—è —Å—Ç–µ–Ω–∞
        floor_color = (160, 160, 165)  # –ß—É—Ç—å —Ç–µ–º–Ω–µ–µ –ø–æ–ª
    else:
        # –¢—ë–º–Ω–∞—è —Å—Ç—É–¥–∏—è
        wall_color = (45, 42, 40)
        floor_color = (35, 32, 30)
    
    horizon = int(height * 0.7)
    transition_height = int(height * 0.15)
    
    # –°—Ç–µ–Ω–∞ —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–º
    for y in range(horizon):
        t = y / horizon
        factor = 1.0 - t * 0.08  # –ù–µ–±–æ–ª—å—à–æ–µ –∑–∞—Ç–µ–º–Ω–µ–Ω–∏–µ –∫ –≥–æ—Ä–∏–∑–æ–Ω—Ç—É
        color = tuple(int(c * factor) for c in wall_color)
        bg[y, :] = color
    
    # S-–æ–±—Ä–∞–∑–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥ (cyclorama curve)
    for y in range(horizon, min(horizon + transition_height, height)):
        t = (y - horizon) / transition_height
        s = t * t * (3 - 2 * t)  # smoothstep
        color = tuple(int(wall_color[i] * (1 - s) + floor_color[i] * s) for i in range(3))
        bg[y, :] = color
    
    # –ü–æ–ª —Å –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–º –∑–∞—Ç–µ–º–Ω–µ–Ω–∏–µ–º
    for y in range(horizon + transition_height, height):
        t = (y - horizon - transition_height) / (height - horizon - transition_height + 1)
        factor = 1.0 - t * 0.15
        color = tuple(int(c * factor) for c in floor_color)
        bg[y, :] = color
    
    # –ú—è–≥–∫–æ–µ —Ä–∞–∑–º—ã—Ç–∏–µ
    bg = cv2.bilateralFilter(bg, 9, 75, 75)
    
    return bg


def composite_on_background(foreground_bgr, mask, background):
    """–ö–æ–º–ø–æ–∑–∏—Ç–∏–Ω–≥ –Ω–∞ —Ñ–æ–Ω —Å —É—á—ë—Ç–æ–º –º–∞—Å–∫–∏"""
    if mask.ndim == 2:
        mask_3ch = np.stack([mask] * 3, axis=-1)
    else:
        mask_3ch = mask
    
    fg = foreground_bgr.astype(np.float32)
    bg = cv2.resize(background, (foreground_bgr.shape[1], foreground_bgr.shape[0])).astype(np.float32)
    mask_f = mask_3ch.astype(np.float32)
    if mask_f.max() > 1:
        mask_f = mask_f / 255.0
    
    result = fg * mask_f + bg * (1 - mask_f)
    return np.clip(result, 0, 255).astype(np.uint8)
```

#### –Ø—á–µ–π–∫–∞ 6: –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ
```python
input_video = "/content/squat_cropped.mp4"
output_video = "/content/squat_processed.mp4"

cap = cv2.VideoCapture(input_video)
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

print(f"üìπ –í–∏–¥–µ–æ: {width}x{height}, {fps} fps, {total_frames} –∫–∞–¥—Ä–æ–≤")

# –ü–∞–¥–¥–∏–Ω–≥ –¥–ª—è MODNet (—Ç—Ä–µ–±—É–µ—Ç —Ä–∞–∑–º–µ—Ä –∫—Ä–∞—Ç–Ω—ã–π 32)
def pad_to_multiple(img, multiple=32):
    h, w = img.shape[:2]
    new_h = ((h + multiple - 1) // multiple) * multiple
    new_w = ((w + multiple - 1) // multiple) * multiple
    pad_h, pad_w = new_h - h, new_w - w
    if len(img.shape) == 3:
        return np.pad(img, ((0, pad_h), (0, pad_w), (0, 0)), mode='reflect'), (h, w)
    return np.pad(img, ((0, pad_h), (0, pad_w)), mode='reflect'), (h, w)

# –°–í–ï–¢–õ–ê–Ø cyclorama!
background = create_cyclorama_background(width, height, style="light")

fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))

max_frames = None  # –∏–ª–∏ 100 –¥–ª—è —Ç–µ—Å—Ç–∞

from tqdm import tqdm
frame_count = 0

with tqdm(total=min(total_frames, max_frames or total_frames)) as pbar:
    while True:
        ret, frame = cap.read()
        if not ret or (max_frames and frame_count >= max_frames):
            break
        
        # MODNet –º–∞—Å–∫–∞
        frame_padded, orig_size = pad_to_multiple(frame, 32)
        img_pil = Image.fromarray(cv2.cvtColor(frame_padded, cv2.COLOR_BGR2RGB))
        tensor = transform(img_pil).unsqueeze(0).cuda()
        
        with torch.no_grad():
            _, _, mask_tensor = modnet(tensor, True)
        
        mask = mask_tensor[0, 0].cpu().numpy()[:orig_size[0], :orig_size[1]]
        
        # V11 –æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed = process_frame_v11(frame, mask)
        
        # –ö–æ–º–ø–æ–∑–∏—Ç–∏–Ω–≥
        final = composite_on_background(processed, mask, background)
        
        out.write(final)
        frame_count += 1
        pbar.update(1)

cap.release()
out.release()
print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! {frame_count} –∫–∞–¥—Ä–æ–≤ ‚Üí {output_video}")
```

#### –Ø—á–µ–π–∫–∞ 7: –ü—Ä–µ–≤—å—é –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
```python
import matplotlib.pyplot as plt

# –ü—Ä–µ–≤—å—é
cap = cv2.VideoCapture(output_video)
fig, axes = plt.subplots(1, 4, figsize=(20, 6))
for i, idx in enumerate([0, total_frames//4, total_frames//2, 3*total_frames//4]):
    cap.set(cv2.CAP_PROP_POS_FRAMES, min(idx, frame_count-1))
    ret, frame = cap.read()
    if ret:
        axes[i].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        axes[i].set_title(f'–ö–∞–¥—Ä {idx}')
        axes[i].axis('off')
cap.release()
plt.show()

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ H.264 –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
!ffmpeg -y -i {output_video} -c:v libx264 -preset fast -crf 23 /content/squat_final.mp4

from google.colab import files
files.download('/content/squat_final.mp4')
```

---

## 3. V11 –ù–∞—Å—Ç—Ä–æ–π–∫–∏ (—Ñ–∏–Ω–∞–ª—å–Ω—ã–µ)

–≠—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞—é—Ç **–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π** –≤–∏–¥ –±–µ–∑ "–ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–≥–æ" —ç—Ñ—Ñ–µ–∫—Ç–∞:

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|----------|
| brightness_boost | 0.08 | +8% —è—Ä–∫–æ—Å—Ç–∏ |
| contrast | 1.12 | +12% –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ |
| lab_lift | 52 | –û—Å–≤–µ—Ç–ª–µ–Ω–∏–µ —Ç–µ–Ω–µ–π < 52 –≤ LAB |
| skin_saturation_boost | 15 | –ù–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å –∫–æ–∂–∏ |
| red_boost | 1.03 | –¢—ë–ø–ª—ã–π –æ—Ç—Ç–µ–Ω–æ–∫ (–∫—Ä–∞—Å–Ω—ã–π +3%) |
| blue_reduce | 0.97 | –¢—ë–ø–ª—ã–π –æ—Ç—Ç–µ–Ω–æ–∫ (—Å–∏–Ω–∏–π -3%) |

---

## 4. Cyclorama —Ñ–æ–Ω

**–°–≤–µ—Ç–ª–∞—è —Å—Ç—É–¥–∏—è (style="light"):**
- –°—Ç–µ–Ω–∞: RGB(180, 180, 185) ‚Äî —Å–≤–µ—Ç–ª–æ-—Å–µ—Ä–∞—è
- –ü–æ–ª: RGB(160, 160, 165) ‚Äî —á—É—Ç—å —Ç–µ–º–Ω–µ–µ

**–¢—ë–º–Ω–∞—è —Å—Ç—É–¥–∏—è (style="dark"):**
- –°—Ç–µ–Ω–∞: RGB(45, 42, 40)
- –ü–æ–ª: RGB(35, 32, 30)

**–≠—Ñ—Ñ–µ–∫—Ç—ã:**
- –ì–æ—Ä–∏–∑–æ–Ω—Ç –Ω–∞ 70% –≤—ã—Å–æ—Ç—ã
- S-curve –ø–µ—Ä–µ—Ö–æ–¥ (smoothstep) –º–µ–∂–¥—É —Å—Ç–µ–Ω–æ–π –∏ –ø–æ–ª–æ–º
- –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–µ –∑–∞—Ç–µ–º–Ω–µ–Ω–∏–µ –∫ –∫—Ä–∞—è–º
- Bilateral filter –¥–ª—è –º—è–≥–∫–æ—Å—Ç–∏

---

## 5. –í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã

### MODNet —Ç—Ä–µ–±—É–µ—Ç –ø–∞–¥–¥–∏–Ω–≥
–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–µ–Ω 32. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `pad_to_multiple()`.

### Autocrop 80% vs 90%
- `--fit 80` ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π crop, –º–æ–≥—É—Ç –æ–±—Ä–µ–∑–∞—Ç—å—Å—è –∫—Ä–∞–π–Ω–∏–µ –ø–æ–∑—ã
- `--fit 90` ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ, –±–æ–ª—å—à–µ –∑–∞–ø–∞—Å–∞

### –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
- Tesla T4: ~10 fps (5000 –∫–∞–¥—Ä–æ–≤ ‚âà 8-10 –º–∏–Ω—É—Ç)
- –ë–µ–∑ GPU: –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ, –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è

---

## 6. –§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞

```
/Users/user/Documents/pers2/
‚îú‚îÄ‚îÄ autocrop_video.py          # –õ–æ–∫–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∫–∞–¥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
‚îú‚îÄ‚îÄ smart_mirror_config.py     # V11 –∫–æ–Ω—Ñ–∏–≥ + —Ñ—É–Ω–∫—Ü–∏–∏
‚îú‚îÄ‚îÄ colab_relighting_pipeline.ipynb  # –û—Å–Ω–æ–≤–Ω–æ–π notebook
‚îú‚îÄ‚îÄ squat.mp4                  # –ò—Å—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ
‚îú‚îÄ‚îÄ squat_cropped.mp4          # –ü–æ—Å–ª–µ autocrop
‚îî‚îÄ‚îÄ SMART_MIRROR_PIPELINE.md   # –≠—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

---

## 7. Quick Start

```bash
# 1. –õ–æ–∫–∞–ª—å–Ω–æ: –æ–±—Ä–µ–∑–∫–∞
python3 autocrop_video.py squat.mp4 squat_cropped.mp4 --fit 85

# 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å squat_cropped.mp4 –Ω–∞ Google Drive

# 3. –í Colab: –∑–∞–ø—É—Å—Ç–∏—Ç—å —è—á–µ–π–∫–∏ 1-7

# 4. –°–∫–∞—á–∞—Ç—å squat_final.mp4
```
